{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# We are using the CIFAR-10 dataset\n",
    "\n",
    "# Use the same transforms and data augmentation as the ResNet18 model during training\n",
    "transform = models.ResNet18_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "# Load built-in CIFAR-10 dataset (torchvision)\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./CIFAR10_data\", train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./CIFAR10_data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Classes from CIFAR-10 dataset\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18 model\n",
    "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Change the last fully connected layer to output 10 classes\n",
    "num_ftrs = model_ft.fc.in_features # Number of input features for the last layer\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(classes))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# All parameters are being optimized (fine-tuning!)\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [2000/12500], Loss: 1.3118975162506104\n",
      "Epoch [1/2], Step [4000/12500], Loss: 1.064820408821106\n",
      "Epoch [1/2], Step [6000/12500], Loss: 1.7125447988510132\n",
      "Epoch [1/2], Step [8000/12500], Loss: 2.1971778869628906\n",
      "Epoch [1/2], Step [10000/12500], Loss: 0.5122009515762329\n",
      "Epoch [1/2], Step [12000/12500], Loss: 0.32774579524993896\n",
      "Epoch [2/2], Step [2000/12500], Loss: 0.5738235712051392\n",
      "Epoch [2/2], Step [4000/12500], Loss: 0.2700616121292114\n",
      "Epoch [2/2], Step [6000/12500], Loss: 0.01647564023733139\n",
      "Epoch [2/2], Step [8000/12500], Loss: 0.21853423118591309\n",
      "Epoch [2/2], Step [10000/12500], Loss: 0.2566913068294525\n",
      "Epoch [2/2], Step [12000/12500], Loss: 0.11422920227050781\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024 meaning 4 images, 3 channels (RGB), 32x32 pixels\n",
    "        # input_layer: 3 input channels (RGB), 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_ft(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer_ft.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8498\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1000\n",
      "           1       0.96      0.90      0.93      1000\n",
      "           2       0.81      0.82      0.82      1000\n",
      "           3       0.73      0.77      0.75      1000\n",
      "           4       0.96      0.76      0.85      1000\n",
      "           5       0.87      0.71      0.78      1000\n",
      "           6       0.72      0.94      0.81      1000\n",
      "           7       0.90      0.86      0.88      1000\n",
      "           8       0.88      0.92      0.90      1000\n",
      "           9       0.90      0.92      0.91      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.86      0.85      0.85     10000\n",
      "weighted avg       0.86      0.85      0.85     10000\n",
      "\n",
      "Confusion Matrix: [[886   6  22  15   1   1   7   4  43  15]\n",
      " [  7 903   4   2   0   0   7   1  18  58]\n",
      " [ 35   2 822  47   9   8  63   7   6   1]\n",
      " [ 17   1  38 767   4  54  89  16  10   4]\n",
      " [ 20   0  46  55 758  16  70  25   8   2]\n",
      " [  5   1  33 106   3 713  85  42   8   4]\n",
      " [  8   1  18  20   1   6 940   0   4   2]\n",
      " [ 19   0  25  25  14  18  28 863   6   2]\n",
      " [ 35   8   3  10   0   1   6   0 922  15]\n",
      " [ 12  22   4   4   0   0  12   3  19 924]]\n",
      "Class 0 (plane) accuracy: 0.886\n",
      "Class 1 (car) accuracy: 0.903\n",
      "Class 2 (bird) accuracy: 0.822\n",
      "Class 3 (cat) accuracy: 0.767\n",
      "Class 4 (deer) accuracy: 0.758\n",
      "Class 5 (dog) accuracy: 0.713\n",
      "Class 6 (frog) accuracy: 0.94\n",
      "Class 7 (horse) accuracy: 0.863\n",
      "Class 8 (ship) accuracy: 0.922\n",
      "Class 9 (truck) accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model_ft(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true += labels.tolist()\n",
    "        y_pred += predicted.tolist()\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_true, y_pred)}\")\n",
    "print(f\"Classification Report: {classification_report(y_true, y_pred)}\")\n",
    "print(f\"Confusion Matrix: {confusion_matrix(y_true, y_pred)}\")\n",
    "for i in range(10):\n",
    "    print(f\"Class {i} ({classes[i]}) accuracy: {accuracy_score(np.array(y_true)[np.array(y_true) == i], np.array(y_pred)[np.array(y_true) == i])}\")\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model_ft.state_dict(), \"model.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BA_Benedikt_Wille",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
